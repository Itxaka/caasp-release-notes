
include::attributes.adoc[]
include::entities.adoc[]

= {productname} {productversion} Release Notes

ifeval::['{release_type}' != 'public']
[WARNING]
!!! This is a preview release. Not to be distributed outside of SUSE !!!
endif::[]

[WARNING]
This software is not ready for production use.

[NOTE]
The released version is {productname} {productversion}


== Supported Platforms

This release supports deployment on

* {soc} 8
* VMWare ESXi {vmware_version}

* Bare metal

== New in {productname} {productversion}

=== Platform Upgrades Using Skuba

Updates for the core packages and containers are orchestrated with
`skuba cluster upgrade plan`, `skuba node upgrade plan` and `skuba node
upgrade apply`. These new `skuba` subcommands allow the administrator to
check the availability of platform upgrades within the cluster and trace
a plan to get the cluster upgraded. The upgrade plan will show the packages
upgrade path and steps that are required for each node to be upgraded. Then
`skuba node upgrade apply` will execute the upgrade plan on the selected node.

See the platfrom upgrades documentation: https://susedoc.github.io/doc-caasp/beta/caasp-admin/single-html/#_cluster_updates

==== Upgrade from Previous 4.0.0 Beta 3 Release

The current beta release allows to upgrade from previous {productname} 4.0.0 Beta 3 to
the current {productversion} release. Using new `skuba` features such as
`upgrade plan` and `upgrade apply`, is possible on top of the previous 4.0.0 Beta 3
following the procedure documented in: https://susedoc.github.io/doc-caasp/beta/caasp-admin/single-html/#_applying_updates

[NOTE]
====
Note this is a temporary procedure likely to change in further releases.
====

=== Role Based Access Control (RBAC)

The authentication components are deployed with {productname} installation.
Administrators can update LDAP identity providers before or after platform
deployment. After your {productname} deployment, administrators can then
use {kube} RBAC to design user or group authorization. Users can access
with a web browser to do the authentication and self-configure kubectl to
access authorized resources.

See the RBAC documentation: https://susedoc.github.io/doc-caasp/beta/caasp-admin/single-html/#_role_based_access_control_rbac

=== {kube} Stack

{productname} {productversion} ships with {kube} {kube_version}.

With {kube} {kube_version} CaaSP is currently aligned with {kube}
upstream release. In addition, with the current {kube} version {productname}
{productversion} clusters are passing Sonobuoy {kube} conformance tests.

=== Added Supportconfig plugin for CaaSP

Supportconfig is the standard way of collecting relevant system information
of SUSE products. It produces a TAR archive that can be handed over the
techincal support.

Running the command `supportconfig -ipsuse_caasp` in platform and worker nodes
generates a `/var/log/nts_*.txz` archive with system information including
{kube} and CRI-O logs.

== New in {productname} 4.0.0

=== Base Operating System Now {SLE} 15 SP1

The previous version used a minimal OS image called MicroOS. {productname}
{productmajor} uses standard {sle} Server 15 SP1 as the base platform OS.
{productname} can be installed as an extension on top of that.

Because {sle} 15 is designed to address both cloud native and legacy workloads,
these changes make it easier for customers who want to modernize their
infrastructure by moving existing workloads to a {kube} framework.

Transactional-updates are available as a technical preview but {productname}
{productmajor} will initially ship without the transactional-update mechanism enabled.
The regular zypper workflow allows use of interruption free node reboot.
The SLES update process should help customers integrate a {kube} platform
into their existing operational infrastructure more easily, nevertheless transactional
updates are still the preferred process for some customers,
which is why we provide both options.

=== Software Now Shipped As Packages Instead Of Disk Image

In the previous version the deployment of the software was done by downloading and installing a disk
image with a pre-baked version of the product. In {productname} {productmajor} the software is distributed
as RPM packages from an extension module in {sle} 15 SP1.
This adaptation towards containers and {sles} mainly gives customers more deployment flexibility.

=== Components Even More Containerized

We moved more of the components into containers, namely all the control plane components:
`etcd`, `kube-apiserver`, `kube-controller-manager` and `kube-scheduler`.
The only pieces that are now running uncontainerized are `CRI-O`, `kubelet` and `kubeadm`.

=== New Deployment Methods

We are using a combination of `skuba` (custom wrapper around kubeadm) and
HashiCorp Terraform to deploy SUSE CaaS Platform machines and clusters.
We provide terraform state examples that you can modify to roll out clusters.

Deployment on Bare metal using AutoYaST has now also been tested and documented:
https://susedoc.github.io/doc-caasp/beta/caasp-deployment/single-html/#_deployment_on_bare_metal

Note: You must roll out a load balancer manually,
this is currently not possible by using terraform.
Find an example of a possible load balancer configuration
based on SUSE Linux Enterprise 15 SP1 and nginx in the Deployment guide:
https://susedoc.github.io/doc-caasp/beta/caasp-deployment/single-html/#_load_balancer


=== Updates Using Kured

Updates are implemented with `skuba-update`, that makes use of the `kured`
tool and the SLE package manager. This is implemented in the skuba-update
tool which glues zypper and the kured tool (https://github.com/weaveworks/kured).
Kured (KUbernetes REboot Daemon) is a {kube} daemonset that performs safe
automatic node reboots when the need to do so is indicated by the package
management system of the underlying OS. Automatic updates can be manually
disabled and configured: https://susedoc.github.io/doc-caasp/beta/caasp-admin/single-html/#_cluster_updates

=== Updated Kubernetes

{productname} {productversion} ships with {kube} {kube_version}.
This latest version mainly contains enhancements to core {kube} APIs:
CustomResourceDefinitions Pruning, -Defaulting and -OpenAPI publishing.

Cluster life cycle stability and usability has been enhanced
(`kubeadm init` and `kubeadm join` can now be used to configure and deploy an HA control plane)
and new functionality of the Container Storage Interface (volume cloning) is available.

Read up about the details of the new features of {kube} {kube_version} here:
https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG-1.15.md#115-whats-new

=== CRI-O Replaces Docker

{productname} now uses CRI-O {crio_version} as the default container runtime.
CRI-O is a container runtime interface based on the OCI standard technology.
The choice of CRI-O allows us to pursue our open-source agenda better than competing technologies.

CRI-O's simplified architecture is tailored explicitly for {kube} and has a reduced footprint but also
guarantees full compatibility with existing customer images thanks to its adherence to OCI standards.
Other than Docker, CRI-O allows to update the container runtime without stopping workloads;
providing improved flexibility and maintainabilitty to all {productname} users.

We will strive to maintain {productname}'s compatibility with Docker in the future.

=== Cilium Replaces Flannel

{productname} now uses Cilium {cilium_version} as the Container Networking
Interface enabling networking policy support.

=== Centralized logging

The deployment of a Centralized Logging node is now supported for the purpose of
aggregating logs from all the nodes in the {kube} cluster.
Centralized Logging forwards system and {kube} cluster logs to a
specified external logging service, specifically the Rsyslog server,
using {kube} Metadata Module - `mmkubernetes`.

== Obsolete Components

=== Salt

Orchestration of the cluster no longer relies on Salt.
Orchestration is instead achieved with `kubeadm` and `skuba`.

=== Admin Node / Velum

The Admin Node is no longer necessary. The cluster will now be controlled
by the master nodes and through API with `skuba` on the local workstation.
This also means the Velum dashboard is no longer available.

== Fixed Issues in this Beta Release

* https://bugzilla.suse.com/show_bug.cgi?id=1138908 - `skuba node remove` removes the node only temporarily until you restart.
* https://bugzilla.suse.com/show_bug.cgi?id=1138859 - Terraform network variables are not interpolated. QA?
* https://bugzilla.suse.com/show_bug.cgi?id=1138267 - conntrack binary is missing for kube-proxy. QA?
* https://bugzilla.suse.com/show_bug.cgi?id=1137591 - Failed disarming kubelet during node removal.

== Known Issues

* https://bugzilla.suse.com/show_bug.cgi?id=1137333 - kubernetes-client not present in Management pattern (kubectl).
* https://bugzilla.suse.com/show_bug.cgi?id=1137628 - Multiple coredns containers running on master node.
* https://bugzilla.suse.com/show_bug.cgi?id=1138139 - Node removal freezes on drain without timeout.
* https://bugzilla.suse.com/show_bug.cgi?id=1141131 - skuba-update is installed by the CaaSP Management pattern
* https://bugzilla.suse.com/show_bug.cgi?id=1137879 - All cilium pods are terminated & replaced after adding worker node.
